# -*- coding: utf-8 -*-
"""RECOMENDATION SYSTEM MOVIE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IxAHKWeNUDhj4odncZCjrXQiH-QsAMND

# Laporan Poroyek Machine Learning - Dwi Krisnandi

Submission 2 Machine Learning Terapan - Sistem Rekomendasi Film

## Project Overview

Proyek pengembangan sistem rekomendasi film sangat penting untuk diselesaikan karena dapat meningkatkan pengalaman pengguna dengan memberikan rekomendasi yang lebih sesuai dengan minat, mengatasi masalah informasi berlebih yang sering dihadapi pengguna, serta memberikan manfaat ekonomi yang signifikan bagi perusahaan streaming. Sistem rekomendasi yang efektif dapat membantu pengguna menemukan film yang sesuai dengan preferensi mereka, sehingga mengurangi waktu pencarian dan meningkatkan kepuasan pengguna secara keseluruhan. Penelitian menunjukkan bahwa algoritma rekomendasi berbasis machine learning dapat meningkatkan akurasi dan kinerja rekomendasi, sementara sistem yang baik dapat menghemat biaya dan meningkatkan retensi pelanggan, seperti yang dialami oleh Netflix yang mengklaim menghemat sekitar $1 miliar per tahun berkat algoritma rekomendasi mereka. Selain itu, pemahaman yang lebih dalam tentang interaksi pengguna dengan algoritma rekomendasi dapat membantu pengembang menciptakan sistem yang lebih adaptif dan responsif terhadap kebutuhan pengguna, menjadikan proyek ini tidak hanya bermanfaat bagi pengguna tetapi juga memberikan keuntungan yang substansial bagi industri hiburan secara keseluruhan.

Sumber :
1. Zhang, "Movie Recommendation System Based on Machine Learning," *Highlights in Business Economics and Management* (2023). doi:10.54097/hbem.v21i.14740. Penelitian ini menunjukkan bagaimana sistem rekomendasi berbasis machine learning dapat meningkatkan akurasi dan kinerja rekomendasi dengan mengintegrasikan tag fitur.

2. Singh, A., & Soundarabai, "Collaborative filtering in movie Recommendation System based on Rating and Genre," *Ijarcce* (2017). doi:10.17148/ijarcce.2017.63107. Artikel ini membahas bagaimana sistem rekomendasi membantu merekomendasikan item berdasarkan kebutuhan pengguna yang bervariasi, mengurangi kebingungan dalam pencarian konten.

## Bussiness Understanding

**Problem Statements**

Dalam konteks proyek rekomendasi film, pernyataan masalah yang dihadapi adalah kesulitan pengguna dalam menemukan film yang sesuai dengan preferensi diantara banyaknya pilihan yang tersedia.

**Goals**

Tujuan dari proyek ini adalah untuk mengembangkan sistem rekomendasi film yang dapat memberikan saran yang relevan dan personal kepada pengguna. Diharapkan pengguna dapat dengan mudah menemukan film yang sesuai dengan selera merek.

**Solution Approach**

Untuk mencapai tujuan tersebut, dua pendekatan solusi yang dapat diterapkan adalah:

1. **Content-Based Filtering**: Pendekatan ini berfokus pada analisis karakteristik film yang telah ditonton oleh pengguna sebelumnya.

2. **Collaborative Filtering**: Pendekatan ini memanfaatkan data interaksi pengguna dengan film, seperti rating yang diberikan, untuk menemukan pola dan kesamaan antara pengguna.

## Data Understanding

### Download dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import json

# Membuat file kaggle.json dengan API token Anda
api_token = {"username":"krisnandi9998","key":"2d15c9eb5dd2bb51786765892d7218d9"}

# Membuat folder kaggle dan menyimpan token API
!mkdir -p ~/.kaggle
with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)

# Mengubah izin akses untuk file API
!chmod 600 ~/.kaggle/kaggle.json

# Unduh dataset menggunakan API Kaggle
!kaggle datasets download -d rohan4050/movie-recommendation-data

"""pada tahapan diatas adalah proses download dataset dari dengan menggunakan API Kaggle dan menghasilkan file dengan nama `movie-recommendation-data.zip`

### Ekstrak dataset
"""

!unzip movie-recommendation-data.zip -d /content/movie

"""setelah di download dan mendapatkan file yang bernama movie-recommendation-data.zip dan kemudia di ekstrak kedalam folder `content/movie` dan berisikan beberapa file diantaranya
1. `movies_metadata.csv`
2. `links.csv`
3. `movies.csv`
4. `ratings.csv`
5. `tags.csv`

untuk file nomor 2 sampai 5 berada didalam folder `ml-latest-small`

### Membaca dataset
"""

# Load dataset
path = 'movie/ml-latest-small/'
df_rating = pd.read_csv(path + 'ratings.csv')
df_movies = pd.read_csv(path + 'movies.csv')
df_links = pd.read_csv(path + 'links.csv')
df_tags = pd.read_csv(path + 'tags.csv')

"""pada kode di atas  dilakukan deklarasi variabel untuk setiap dataset yang akan dipakai dengan menggunakan `Pandas` dalam fungsi `read_csv`"""

print('Jumlah data link movie : ', len(df_links.movieId.unique()))
print('Jumlah data movie : ', len(df_movies.movieId.unique()))
print('Jumlah data ratings dari user : ', len(df_rating.userId.unique()))
print('Jumlah data ratings dari movie : ', len(df_rating.movieId.unique()))
print('Jumlah data tags : ', len(df_tags.movieId.unique()))

"""kode di atas memberikan informasi jumlah setiap variabel yang akan dipakai dengan penjelasan :
1. `link` yaitu daftar link pada setiap film
2. `movie` merupakan daftar film yang tersedia untuk sistem ini
3. `ratings` yaitu daftar penilaian dari film yang derikan pengguna
4. `tags` adalah daftar kata kunci dari film yang ada
"""

df_links.info()

"""DataFrame link berisi 9742 baris dan 3 kolom, yaitu movieId, imdbId, dan tmdbId. Kolom movieId dan imdbId lengkap (tidak ada data yang hilang), sedangkan kolom tmdbId memiliki 8 nilai yang hilang. Tipe data untuk movieId dan imdbId adalah integer, sementara tmdbId adalah float (bilangan desimal). Total memori yang digunakan adalah sekitar 228.5 KB."""

df_movies.info()

"""DataFrame movies berisi 9742 baris dan 3 kolom, yaitu movieId, title, dan genres. Semua kolom memiliki data yang lengkap (tidak ada nilai yang hilang). Tipe data untuk movieId adalah integer, sedangkan title dan genres disimpan dalam format string (object). Total memori yang digunakan oleh DataFrame ini adalah lebih dari 228.5 KB."""

df_rating.info()

"""DataFrame rating berisi 100836 baris dan 4 kolom, yaitu userId, movieId, rating, dan timestamp. Semua kolom memiliki data yang lengkap (tidak ada nilai yang hilang). Tipe data untuk userId, movieId, dan timestamp adalah integer, sementara rating adalah float (bilangan desimal). Total memori yang digunakan oleh DataFrame ini adalah sekitar 3.1 MB"""

df_tags.info()

"""DataFrame ini berisi 3683 baris dan 4 kolom, yaitu userId, movieId, tag, dan timestamp. Semua kolom memiliki data yang lengkap (tidak ada nilai yang hilang). Tipe data untuk userId, movieId, dan timestamp adalah integer, sementara tag disimpan dalam format string (object). Total memori yang digunakan oleh DataFrame ini adalah lebih dari 115.2 KB.

kode ini bertujuan untuk melihat variabel dalam data rating
"""

# Visualisasi distribusi rating
plt.figure(figsize=(10, 6))
sns.histplot(df_rating['rating'], bins=20, kde=True, color='blue')
plt.title("Distribusi Rating")
plt.xlabel("Rating")
plt.ylabel("Frekuensi")
plt.show()

"""dari hasil visualisi dapat diketahui bahwa rating berada diantara range 0-5 dengan frekuaensi paling banyak di kisaran 26.000"""

# Visualisasi distribusi genre
plt.figure(figsize=(10, 6))
df_movies['genres'].value_counts().head(10).plot(kind='bar', color='purple')
plt.title("Distribusi 10 Genre Teratas")
plt.xlabel("Genre")
plt.ylabel("Jumlah Film")
plt.xticks(rotation=45)
plt.show()

"""Dari hasil visualisasi di atas dapat diketahui 10 genre terbanyak dalam dataset ini dan genre **Drama** paling banyak dengan kisaran data 1000 lebih

## Data Preparation

### Data Preprocessing

Menggabungkan semua data dari beberapa file csv dengan fungsi `concate` berdasarkan `movieId` kedalam variabel `movie_all`
"""

import numpy as np

# Menggabungkan seluruh movieID pada kategori movie
movie_all = np.concatenate((
    df_links.movieId.unique(),
    df_movies.movieId.unique(),
    df_rating.movieId.unique(),
    df_tags.movieId.unique(),
))

# Mengurutkan data dan menghapus data yang sama
movie_all = np.sort(np.unique(movie_all))

print('Jumlah seluruh data movie berdasarkan movieID: ', len(movie_all))

"""hasil dari penggabungan movie didapat sebanyak 9742 data

Menggabungkan semua data dari beberapa file csv dengan fungsi `concate` berdasarkan `userId` kedalam variabel `user_all`
"""

# Menggabungkan seluruh userId
user_all = np.concatenate((
    df_rating.userId.unique(),
    df_tags.userId.unique(),

))

# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user: ', len(user_all))

"""hasil dari penggabungan `user_all` didapat sebanyak 610 data"""

all_movie_name = pd.merge(df_rating, df_movies[['movieId','title','genres']], on='movieId', how='left')
all_movie_name

"""kode di atas bertujuan menggabungkan rating dengan movie berdasarkan movieId"""

# Menggabungkan dataframe genres dengan all_movie_name dan memasukkannya ke dalam variabel all_movie
all_movie = pd.merge(all_movie_name, df_tags[['movieId','tag']], on='movieId', how='left')
all_movie

"""Menggabungkan dataframe tags dengan all_movie_name berdasarkan movieId dan memasukkannya ke dalam variabel all_movie

### Mengatasi Missing Value
"""

all_movie.isnull().sum()

"""dari hasil diatas terlihat ada data kosong dengan jumlah 52549 data dalam kolom tag"""

all_movie_clean = all_movie.dropna()
all_movie_clean.isnull().sum()

"""kode di atas dilakuakn penghapusan missing value dengan `dropna` yang bertujuan menghapus semua nilai kosong dalam dataset dan memasukan kedalam variabel baru yaitu `all_movie_clean`"""

print('Jumlah Setelah dibersihkan')
all_movie_clean.info()
print('\n')
print('Jumlah Sebelum dibersihkan')
all_movie.info()

"""data di atas beruabh menjadi 233213 baris yang awalnya 285762 baris"""

fix_movie = all_movie_clean.sort_values('movieId', ascending=True)
fix_movie

"""kode diatas membuat variabel preparation yang berisi dataframe fix_movie kemudian mengurutkan berdasarkan movieId"""

preparation = fix_movie
preparation.sort_values('movieId')

"""kode di atas membuat variabel preparation yang berisi dataframe fix_movie kemudian mengurutkan berdasarkan movieId"""

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movieId')
preparation

"""Selanjutnya untuk kode di atas, gunakan data unik untuk dimasukkan ke dalam proses pemodelan. serta hapus data duplicate dengan fungsi drop_duplicates() berdasarkan movieId"""

# Mengonversi data series ‘movieId’ menjadi dalam bentuk list
movie_id = preparation['movieId'].tolist()

# Mengonversi data series ‘title’ menjadi dalam bentuk list
movie_name = preparation['title'].tolist()

# Mengonversi data series ‘genres’ menjadi dalam bentuk list
movie_genre = preparation['genres'].tolist()

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

"""kode di atas melakukan konversi data series menjadi list. Dalam hal ini, menggunakan fungsi tolist() dari library numpy. Implementasikan"""

movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""Kode diatasb merukan pembuatan Data Frame baru

Pemilihan kolom `movieId`, `title`, dan `genres` sangat strategis karena:

* Mereka menyediakan identifikasi yang diperlukan untuk setiap film.
* Menyediakan informasi yang dibutuhkan untuk analisis dan rekomendasi.
* Memastikan bahwa sistem rekomendasi dapat berfungsi secara efektif, dengan memberikan hasil yang relevan dan informatif kepada pengguna.

#### Menggunakan TFIDF
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tf.fit(movie_new['genre'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""pada kode diatas bertujuan untuk menginisialisasi `TfidfVectorizer` selanjutnya melakukan perhitungan dan terakhir menampilkan genre kedalam array"""

tfidf_matrix = tf.fit_transform(movie_new['genre'])
tfidf_matrix.shape

"""kode di atas melakukan transformasi ke bentuk matriks"""

tfidf_matrix.todense()

"""Kode `tfidf_matrix.todense()` mengonversi matriks jarang hasil perhitungan TF-IDF menjadi matriks penuh yang menyimpan semua elemen, termasuk elemen nol"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=movie_new.movie_name
).sample(22, axis=1).sample(10, axis=0)

"""Kode diatas membuat DataFrame dari matriks TF-IDF dengan kolom berupa fitur (kata-kata) dan indeks berupa nama film, kemudian secara acak mengambil 22 kolom dan 10 baris dari DataFrame tersebut.

## Modeling and Result

Proses modeling yang lakukan pada data ini adalah dengan membuat algoritma machine learning, yaitu `content based filtering` dan `collabrative filtering`. untuk algoritma `content based filtering` DIbuat dengan apa yang disukai pengguna, sedangkan untuk `content based filtering` DIbuat dengan memanfaatkan tingkat rating dari film tersebut.

### Model Development dengan Content Based Filtering
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Kode `cosine_sim = cosine_similarity(tfidf_matrix)` menghitung dan menyimpan matriks kesamaan kosinus dari matriks TF-IDF untuk mengukur tingkat kesamaan antar dokumen"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_new['movie_name'], columns=movie_new['movie_name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Kode ini bertujuan untuk membangun dan menampilkan matriks `cosine similarity` antar film berdasarkan representasi `TF-IDF` mereka. Dengan menggunakan DataFrame, informasi kesamaan antara film dapat diorganisir dengan cara yang mudah dipahami dan digunakan dalam sistem rekomendasi. Dengan mencetak bentuk DataFrame dan menampilkan sampel acak, Anda dapat dengan cepat memeriksa struktur data dan memvalidasi hasil yang diperoleh dari perhitungan `cosine similarity`.

#### Membuat Rekomendasi

membuat fungsi movie_recommendations dengan beberapa parameter sebagai berikut:

* Nama_movie : Nama judul dari movie tersebut (index kemiripan dataframe).
* Similarity_data : Dataframe mengenai similarity yang telah kita didefinisikan sebelumnya
* Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah `movie_name` dan `genre`.
* k : Banyak rekomendasi yang ingin diberikan.
"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=movie_new[['movie_name', 'genre']], k=10):


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_movie agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_movie, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Fungsi `movie_recommendations` dirancang untuk memberikan rekomendasi film berdasarkan nama film yang dimasukkan oleh pengguna, menggunakan matriks cosine similarity yang sudah dihitung sebelumnya. Fungsi ini mengambil nama film yang dicari dan menemukan indeks film lain yang memiliki kesamaan tertinggi dengan film tersebut menggunakan metode `argpartition`, yang memungkinkan pengambilan elemen teratas tanpa perlu mengurutkan seluruh data. Setelah itu, film yang dicari dihapus dari daftar rekomendasi untuk menghindari duplikasi, dan hasilnya digabungkan dengan DataFrame yang berisi informasi film seperti nama dan genre. Akhirnya, fungsi ini mengembalikan sejumlah `k` rekomendasi teratas dalam bentuk DataFrame, memberikan pengguna alternatif yang relevan berdasarkan preferensi mereka."""

# Mengambil 1 judul film secara acak dari DataFrame movie_new
film = 'Deadpool 2 (2018)'
movie_new[movie_new.movie_name.eq(film)]

"""terapkan kode di atas untuk menemukan rekomendasi movie yang mirip dengan Deadpool 2 (2018) dengan genre yang ada pada tabel yaitu `Action|Comedy|Sci-Fi`."""

movie_recommendations(film)

"""Dari data diatas kita diberkan 10 rekomendasi, dari 10 rekomendasi dapat kita pisahkan dainataranya :
1.  Menampilkan 3 data sangat sesuai dengan genre Film `Deadpool 2 (2018)` yaitu `Action|Comedy|Sci-Fi`
2. Menampilkan 9 data dengan memuat genre `Action` dan `Sci-Fi` didalamnya
3. Menampikan 1 data dengan memuat genre `Comedy` dan `Sci-Fi` didalamnya

Berdasarkan hasil yang diberikan menurut saya **100%** akurasi yang diberikan berdasarkan genre dari film `Deadpool 2 (2018)`.

### Model Development dengan Collaborative Filtering

#### Melakukan data preparation untuk model Collaborative Filtering
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df_rating['userId'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Kode diatas bertujuan mengambil daftar unik dari userId dalam dataframe, lalu membuat dua kamus yaitu satu untuk melakukan encoding dari userId ke angka, dan satu lagi untuk decoding dari angka kembali ke userId."""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df_rating['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Selanjutnya, petakan userId dan movieId ke dataframe yang berkaitan.

# Mapping userId ke dataframe genres
df_rating['genres'] = df_rating['userId'].map(user_to_user_encoded)

# Mapping movieD ke dataframe movies
df_rating['movies'] = df_rating['movieId'].map(movie_to_movie_encoded)

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df_rating['ratings'] = df_rating['rating'].values.astype(np.float32)

min_rating = min(df_rating['rating'])

max_rating = max(df_rating['rating'])

print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Kode diatas mertujuan untuk mengecek beberapa hal dalam data seperti jumlah user, jumlah movie, dan mengubah nilai rating menjadi float, cek nilai minimum dan maximum"""

# Mengacak dataset
df = df_rating.sample(frac=1, random_state=42)
df

"""Kode diatas tersebut mengacak seluruh dataset `df_rating` secara acak menggunakan parameter `frac=1` untuk menjaga ukuran dataset tetap sama dan `random_state=42` agar hasil acakan konsisten setiap kali dijalankan."""

# Membuat variabel x untuk mencocokkan data genres  dan movies menjadi satu value
x = df[['genres', 'movies']].values

# Membuat variabel y untuk membuat ratings dari hasil
y = df['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""dengan kode diatas membagi data dengan 80% data training dan 20% data validasi"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""kode di atas mengimpor librari yang di butuhkan"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movies
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movies bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Kelas RecommenderNet adalah model rekomendasi berbasis TensorFlow yang menggunakan embedding untuk merepresentasikan pengguna dan film. Model ini menghitung skor kesukaan dengan melakukan operasi dot product antara vektor embedding pengguna dan film, kemudian menambahkan bias dari pengguna dan film, lalu mengaplikasikan fungsi aktivasi sigmoid untuk menghasilkan prediksi.

Kode kelas `RecommenderNet`, yang merupakan model neural network yang dibangun menggunakan TensorFlow dan Keras untuk sistem rekomendasi:

1. Definisi Kelas
```
class RecommenderNet(tf.keras.Model):
```
Kelas ini diturunkan dari tf.keras.Model, yang memungkinkan Anda untuk membangun model neural network kustom menggunakan TensorFlow. Ini memberikan struktur dan fungsi yang diperlukan untuk membuat dan melatih model.
2. Inisialisasi Fungsi
```
def __init__(self, num_users, num_movie, embedding_size, **kwargs):
```
* __init__: Merupakan konstruktor yang diubah untuk menginisialisasi objek RecommenderNet.
* Parameter:
  * num_users: Jumlah pengguna dalam dataset.
  * num_movie: Jumlah film dalam dataset.
  * embedding_size: Ukuran vektor embedding yang akan digunakan untuk pengguna dan film.
  * **kwargs: Parameter tambahan yang dapat diteruskan ke superclass.
3. Super Constructor
```
super(RecommenderNet, self).__init__(**kwargs)
```
Memanggil konstruktor superclass untuk memastikan bahwa semua pengaturan dari kelas dasar (tf.keras.Model) juga diterapkan.
4. Layer Embedding
```
self.user_embedding = layers.Embedding(num_users, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=keras.regularizers.l2(1e-6))
self.user_bias = layers.Embedding(num_users, 1)
self.movie_embedding = layers.Embedding(num_movie, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=keras.regularizers.l2(1e-6))
self.movie_bias = layers.Embedding(num_movie, 1)
```
* Layer Embedding:
  * user_embedding: Membuat layer embedding untuk pengguna, yang mengonversi ID pengguna menjadi vektor berdimensi embedding_size. Menggunakan he_normal sebagai initializer untuk distribusi normal, serta menambahkan regularisasi L2 untuk mencegah overfitting.

  * user_bias: Membuat layer embedding untuk bias pengguna, dengan ukuran output 1, yang menambahkan bias untuk setiap pengguna.

  * movie_embedding: Mirip dengan user_embedding, tetapi untuk film, mengonversi ID film menjadi vektor berdimensi embedding_size.

  * movie_bias: Membuat layer embedding untuk bias film, juga dengan ukuran output 1.

5. Metode Call
```
def call(self, inputs):
```
Metode ini mendefinisikan bagaimana model akan menghitung output ketika diberikan input.

6. Mengambil Vektor dan Bias
```
user_vector = self.user_embedding(inputs[:, 0])
user_bias = self.user_bias(inputs[:, 0])
movie_vector = self.movie_embedding(inputs[:, 1])
movie_bias = self.movie_bias(inputs[:, 1])
```
* inputs: Diasumsikan sebagai tensor dengan dua kolom, di mana kolom pertama adalah ID pengguna dan kolom kedua adalah ID film.
* Mengambil vektor embedding dan bias untuk pengguna dan film berdasarkan input yang diberikan.

7. Menghitung Produk Dot
```
dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)
```
tf.tensordot: Menghitung produk dot antara vektor pengguna dan film. Angka 2 menunjukkan bahwa kedua vektor memiliki dua dimensi, sehingga hasilnya adalah skalar.

8. Menjumlahkan Vektor dan Bias
```
x = dot_user_movie + user_bias + movie_bias
```
Menambahkan hasil produk dot dengan bias pengguna dan bias film untuk mendapatkan nilai akhir.

9. Fungsi Aktivasi
```
return tf.nn.sigmoid(x)
```
Menggunakan fungsi aktivasi sigmoid untuk mengubah nilai output menjadi rentang antara 0 dan 1. Ini berguna untuk memprediksi rating, di mana 0 berarti tidak suka dan 1 berarti suka.

## EVALUASI
"""

model = RecommenderNet(num_users, num_movie, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=10e-6),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Kode diatas menginisialisasi model rekomendasi RecommenderNet dengan 50 dimensi embedding, lalu melakukan kompilasi model dengan menggunakan BinaryCrossentropy sebagai fungsi loss, optimizer Adam dengan learning rate sangat kecil (10e-6), dan metrik Root Mean Squared Error (RMSE) untuk mengukur performa model."""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Membuat callback
early_stopping = EarlyStopping(
    monitor='val_root_mean_squared_error',  # memonitor metrik validation loss
    patience=10,  # berhenti jika tidak ada perbaikan selama 5 epoch
    restore_best_weights=True  # mengembalikan bobot model terbaik
)

model_checkpoint = ModelCheckpoint(
    filepath='best_model.keras',  # lokasi penyimpanan model terbaik
    monitor='val_root_mean_squared_error',
    save_best_only=True  # hanya menyimpan model dengan performa terbaik
)

# Memulai training dengan callback
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks=[early_stopping, model_checkpoint]  # menambahkan callback
)

"""Kode di atas melakukan pelatihan model dengan:

* EarlyStopping: Menghentikan pelatihan lebih awal jika performa validasi tidak membaik selama 10 epoch.
* ModelCheckpoint: Menyimpan model terbaik selama pelatihan ke file best_model.keras.

Pelatihan dilakukan dengan 100 epoch, batch size 64, dan menggunakan data validasi (x_val, y_val).
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

rmse = history.history['val_root_mean_squared_error'][-1]
print(f"RMSE: {rmse}")

movie_df = movie_new
df = df_rating


user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]


movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Menampilkan rekomendasi dari user : {}'.format(user_id))
print('===' * 9)
print('Film dengan rating tinggi dari penggunaan')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)

print('----' * 8)
print('10 Teratas rekomendasi')
print('----' * 8)

recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)